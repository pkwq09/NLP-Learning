{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd275e0-27ba-4589-9f8e-4fcb24332e89",
   "metadata": {},
   "source": [
    "### 1.1 词嵌入向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56517b5-42d7-4a9d-8598-ea897b8a4938",
   "metadata": {},
   "source": [
    "程序段1.1：词向量层（Input Embedding）的编程实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58869c38-d5dd-4178-bbd3-938d17d4a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class InputEmbeddings(nn.Module):  # 词向量层\n",
    "\n",
    "    def __init__(self, vocab_size: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model) #创建PyTorch的Embedding层\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
    "        return self.embedding(x.long()) * math.sqrt(self.d_model) #将输入x转换为long类型(确保是整数索引)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71195c2-eef7-41f8-958f-d9d9d811e57c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量编码前torch.Size([4, 8])：\n",
      ", tensor([[ 5187,  8910, 11108,  4598, 16055,  4120, 19649,  5527],\n",
      "        [14470,  8284,  1161, 18348, 19652,  3536,  3066, 17416],\n",
      "        [10857,  2649,  1603,  1797, 16212, 12583,  2065,  4399],\n",
      "        [10251, 16728,   349,  4992, 16588,  9539,  2361, 14609]])\n",
      "词向量编码后torch.Size([4, 8, 4])：\n",
      " tensor([[[ 1.2678e-01,  1.2483e-01, -7.6980e-01, -7.9810e-01],\n",
      "         [-3.0506e+00, -2.6890e+00,  3.1259e+00,  1.1606e+00],\n",
      "         [-1.4637e+00, -5.7394e-01,  1.9243e-01, -1.6307e+00],\n",
      "         [-2.7608e+00, -4.5781e+00, -2.7612e+00,  2.5439e+00],\n",
      "         [ 1.6018e+00, -2.2088e+00,  2.9062e+00,  6.3336e-01],\n",
      "         [ 3.5289e+00,  8.7768e-01, -3.2656e+00, -2.5945e-01],\n",
      "         [-8.6179e-01,  2.1509e+00, -2.2301e+00,  3.0614e+00],\n",
      "         [ 6.8590e-01,  9.4952e-01, -1.3004e+00,  2.5137e+00]],\n",
      "\n",
      "        [[-2.2569e-02, -1.7442e+00, -2.3781e+00,  2.8922e+00],\n",
      "         [-1.3270e+00, -1.4574e+00,  6.1618e-01, -3.8060e+00],\n",
      "         [ 2.5347e-01, -2.9460e-01,  5.7769e-01,  5.0034e+00],\n",
      "         [ 2.4760e-01,  2.8101e-01, -1.1471e+00,  7.2387e-01],\n",
      "         [-5.2856e-01,  1.3450e+00,  1.7629e+00, -2.2042e+00],\n",
      "         [ 7.2549e-02,  8.4356e-01, -1.1964e-01,  1.4330e+00],\n",
      "         [-2.2618e+00, -3.9520e-01,  3.5646e-01,  2.0553e+00],\n",
      "         [ 2.4528e+00, -1.0755e+00, -1.8615e+00,  2.0816e+00]],\n",
      "\n",
      "        [[-3.4159e+00, -4.5413e-01, -1.4723e+00, -2.4430e+00],\n",
      "         [ 2.1183e+00, -2.1882e+00, -1.7412e+00, -3.7617e+00],\n",
      "         [-1.8062e+00,  9.1617e-02, -1.3341e+00,  1.5042e+00],\n",
      "         [ 2.9933e-01,  3.9289e-01, -2.7806e+00,  1.5206e+00],\n",
      "         [ 2.9986e+00,  6.1375e-01,  5.8497e-01, -4.6367e-01],\n",
      "         [-1.2463e+00, -3.0180e+00, -6.0548e-02, -8.7167e-01],\n",
      "         [-8.7468e-02,  2.0567e-01, -3.3047e-02,  7.1875e-04],\n",
      "         [-1.5555e+00,  1.8138e+00, -6.4172e-01,  2.0609e+00]],\n",
      "\n",
      "        [[-2.9846e+00, -4.3003e-01, -8.4122e-01, -1.3400e+00],\n",
      "         [ 3.2017e+00, -2.8915e+00, -2.1447e+00, -9.5247e-02],\n",
      "         [-1.3778e+00,  1.5941e+00,  1.2007e+00,  6.9096e-03],\n",
      "         [-3.5479e+00, -7.3435e-01, -1.7008e+00,  6.4959e-01],\n",
      "         [ 2.5270e-02,  4.3240e-01, -7.4675e-02, -2.4079e+00],\n",
      "         [-2.5455e+00,  1.1737e+00,  6.1036e-01,  1.7397e+00],\n",
      "         [-1.3097e+00,  1.6345e+00,  4.8567e-01,  2.4788e+00],\n",
      "         [-1.1643e+00, -1.0514e+00,  4.4415e-01,  1.3899e+00]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "vocab_size = 21128  # 设置词典大小\n",
    "d_model = 4     # 设置模型维度\n",
    "batch_size = 4   # 设置批次大小\n",
    "seq_len = 8      # 设置序列最大长度\n",
    "# 使用 torch.randint 生成随机整数张量 x，取值范围为 [0, vocab_size),表示输入的序列\n",
    "x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "print(f'词向量编码前{x.shape}：\\n, {x}')  # x的维度应该是 (batch_size, seq_len)\n",
    "input_embedding = InputEmbeddings(vocab_size, d_model)\n",
    "x = input_embedding(x)\n",
    "print(f'词向量编码后{x.shape}：\\n {x}')  # x的维度应该是 (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13b44c-6536-4317-8ac5-f6260afa11b7",
   "metadata": {},
   "source": [
    "### 1.2 位置编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5417f-dda8-445b-a26c-2e77d95bdc60",
   "metadata": {},
   "source": [
    "程序段1.2：位置编码层（Positional Encoding）的编程实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0adf8e6b-c9df-4a69-9f6d-11625d499527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):  # 位置编码层\n",
    "\n",
    "    def __init__(self, seq_len: int, d_model: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 使用 torch.zeros 生成初值为 0 的位置矩阵，维度为：(seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        # 将 pe 的维度扩展为 (1, seq_len, d_model)，第一个维度，表示批次的大小\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # 创建位置张量 (seq_len)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # 计算 position * (10000 ** (2i / d_model) ，2i用 torch.arange(0, d_model, 2) 生成\n",
    "        angle = position / torch.pow(10000, torch.arange(0, d_model, 2).float() / d_model) \n",
    "        # 对 pe 中偶数索引的列应用正弦函数\n",
    "        pe[:, :, 0::2] = torch.sin(angle) \n",
    "        # 对 pe 中奇数索引的列应用余弦函数\n",
    "        pe[:, :, 1::2] = torch.cos(angle)   \n",
    "        # 使用 register_buffer 方法将 pe 注册为一个缓冲区\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        position_encode = self.pe.requires_grad_(False)\n",
    "         # 将位置编码与词向量相加， 得到的形状仍为 (batch, seq_len, d_model)\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        x = self.dropout(x)  # dropout的目的是让输出更具泛化能力\n",
    "        return x, position_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d244f719-6471-40c5-9ebe-a3c42b7fcef1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得到的位置编码torch.Size([1, 8, 4])：\n",
      " tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "         [-0.7568, -0.6536,  0.0400,  0.9992],\n",
      "         [-0.9589,  0.2837,  0.0500,  0.9988],\n",
      "         [-0.2794,  0.9602,  0.0600,  0.9982],\n",
      "         [ 0.6570,  0.7539,  0.0699,  0.9976]]])\n",
      "\n",
      "位置编码与词向量相加后的x torch.Size([4, 8, 4])：\n",
      " tensor([[[ 0.1409,  1.2498, -0.8553,  0.2243],\n",
      "         [-0.0000, -2.3875,  0.0000,  2.4006],\n",
      "         [-0.6160, -1.1001,  0.2360, -0.7011],\n",
      "         [-2.9107, -6.1868, -3.0346,  3.9371],\n",
      "         [ 0.9389, -0.0000,  3.2736,  1.8140],\n",
      "         [ 2.8555,  1.2904, -3.5729,  0.8214],\n",
      "         [-1.2680,  3.4567, -2.4113,  4.5107],\n",
      "         [ 1.4921,  1.8927, -1.3672,  3.9014]],\n",
      "\n",
      "        [[-0.0251, -0.8268, -2.6423,  4.3247],\n",
      "         [-0.5395, -1.0190,  0.6958, -3.1179],\n",
      "         [ 1.2920, -0.0000,  0.6641,  6.6702],\n",
      "         [ 0.4319, -0.7878, -1.2412,  1.9149],\n",
      "         [-1.4282,  0.7682,  2.0032, -1.3389],\n",
      "         [-0.9849,  1.2525, -0.0774,  2.7019],\n",
      "         [-2.8236,  0.0000,  0.4627,  3.3928],\n",
      "         [ 3.4553, -0.3574, -1.9906,  0.0000]],\n",
      "\n",
      "        [[-3.7955,  0.6065, -1.6359, -1.6034],\n",
      "         [ 3.2886, -1.8310, -1.9236, -3.0686],\n",
      "         [-0.9966, -0.3606, -1.4602,  2.7822],\n",
      "         [ 0.4894, -0.6635, -3.0562,  2.8001],\n",
      "         [ 2.4909, -0.0443,  0.6944,  0.5950],\n",
      "         [-0.0000, -3.0382, -0.0117,  0.1412],\n",
      "         [-0.4076,  1.2954,  0.0299,  1.1099],\n",
      "         [-0.9984,  2.8530, -0.6353,  3.3983]],\n",
      "\n",
      "        [[-3.3162,  0.6333, -0.0000, -0.3778],\n",
      "         [ 4.4924, -2.6124, -2.3719,  1.0052],\n",
      "         [-0.0000,  1.3089,  1.3563,  0.0000],\n",
      "         [-3.7854, -1.9159, -1.8565,  1.8324],\n",
      "         [-0.8128, -0.2458, -0.0385, -1.5652],\n",
      "         [-3.8938,  1.6193,  0.7337,  3.0427],\n",
      "         [-1.7657,  2.8829,  0.0000,  3.8633],\n",
      "         [-0.5637, -0.3306,  0.5712,  2.6528]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "dropout = 0.1\n",
    "position_encoding = PositionalEncoding(seq_len, d_model, dropout)\n",
    "x, positon_encode = position_encoding(x)\n",
    "print(f'得到的位置编码{positon_encode.shape}：\\n {positon_encode}') \n",
    "print(f'\\n位置编码与词向量相加后的x {x.shape}：\\n {x}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8a0f2-5843-4937-aeee-280faf95506c",
   "metadata": {},
   "source": [
    "### 1.3 Q、K、V矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de13b2-df35-4362-a766-03735ed3ea65",
   "metadata": {},
   "source": [
    "程序段1.3实现了Q、K、V矩阵的生成逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd139d9-24b5-44bb-9a96-3f0369a62028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q矩阵torch.Size([4, 4])：\n",
      " Parameter containing:\n",
      "tensor([[-0.2306, -0.2550,  0.2075,  0.4690],\n",
      "        [-0.3763, -0.1178, -0.3161, -0.1143],\n",
      "        [-0.2948,  0.1617,  0.3861,  0.2138],\n",
      "        [ 0.0054,  0.2621,  0.0655, -0.2242]], requires_grad=True)\n",
      "W_k矩阵torch.Size([4, 4])：\n",
      " Parameter containing:\n",
      "tensor([[-0.4327,  0.4112, -0.2834,  0.4604],\n",
      "        [ 0.2423, -0.0924, -0.4268, -0.4884],\n",
      "        [ 0.1975,  0.2601, -0.0412,  0.3488],\n",
      "        [-0.1899, -0.2365, -0.2957,  0.3863]], requires_grad=True)\n",
      "W_v矩阵torch.Size([4, 4])：\n",
      " Parameter containing:\n",
      "tensor([[ 0.0900,  0.4058, -0.4526, -0.3298],\n",
      "        [ 0.0822, -0.4185,  0.1396, -0.0061],\n",
      "        [ 0.1199, -0.3806, -0.1170, -0.0273],\n",
      "        [ 0.4441, -0.0816, -0.3588,  0.1857]], requires_grad=True)\n",
      "Q矩阵torch.Size([4, 8, 4])：\n",
      " tensor([[[-0.4234,  0.0446, -0.1217,  0.2220],\n",
      "         [ 1.7346,  0.0067,  0.1271, -1.1641],\n",
      "         [ 0.1427,  0.3669, -0.0550, -0.1190],\n",
      "         [ 3.4653,  2.3331, -0.4724, -2.7189],\n",
      "         [ 1.3135, -1.5956,  1.3750, -0.1873],\n",
      "         [-1.3435, -0.1909, -1.8370, -0.0644],\n",
      "         [ 1.0262,  0.3167,  0.9661, -0.2702],\n",
      "         [ 0.7194, -0.7982,  0.1724, -0.4602]],\n",
      "\n",
      "        [[ 1.6966,  0.4477, -0.2220, -1.3596],\n",
      "         [-0.9337,  0.4595, -0.4037,  0.4747],\n",
      "         [ 2.9682, -1.4588,  1.3016, -1.4453],\n",
      "         [ 0.7418,  0.1037, -0.3246, -0.7148],\n",
      "         [-0.0789, -0.0333,  1.0325,  0.6250],\n",
      "         [ 1.1588, -0.0613,  1.0406, -0.2880],\n",
      "         [ 2.3382,  0.5284,  1.7363, -0.7458],\n",
      "         [-1.1186, -0.6289, -1.8450, -0.2053]],\n",
      "\n",
      "        [[-0.3710,  2.0574,  0.2425,  0.3908],\n",
      "         [-2.1297, -0.0629, -2.6643,  0.1001],\n",
      "         [ 1.3236,  0.5610,  0.2665, -0.8194],\n",
      "         [ 0.7354,  0.5400, -0.8330, -0.9992],\n",
      "         [-0.1398, -1.2197, -0.3461, -0.0861],\n",
      "         [ 0.8384,  0.3453, -0.4656, -0.8288],\n",
      "         [ 0.2904, -0.1355,  0.5785,  0.0904],\n",
      "         [ 0.9647, -0.1480,  1.2369, -0.0613]],\n",
      "\n",
      "        [[ 0.4259,  1.2166,  0.9992,  0.2328],\n",
      "         [-0.3904, -0.7480, -2.4476, -1.0411],\n",
      "         [-0.0523, -0.5829,  0.7354,  0.4319],\n",
      "         [ 1.8354,  2.0275,  0.4810, -1.0551],\n",
      "         [-0.4920,  0.5260, -0.1497,  0.2796],\n",
      "         [ 2.0641,  0.6947,  2.3435, -0.2309],\n",
      "         [ 1.4839, -0.1167,  1.8126, -0.1202],\n",
      "         [ 1.5769, -0.2328,  0.9004, -0.6472]]], grad_fn=<UnsafeViewBackward0>)\n",
      "K矩阵torch.Size([4, 8, 4])：\n",
      " tensor([[[ 0.7986,  0.1741,  0.4664,  0.0173],\n",
      "         [ 0.1234, -0.9518,  0.2162,  1.4918],\n",
      "         [-0.5754,  0.1940, -0.6620,  0.0365],\n",
      "         [ 1.3879, -0.7612, -0.6860,  4.4336],\n",
      "         [-0.4989, -2.0556,  0.6833, -0.4455],\n",
      "         [ 0.6856,  1.6964,  1.3331,  0.5264],\n",
      "         [ 4.7299, -1.8005,  2.3211,  1.8787],\n",
      "         [ 2.3160, -1.1353,  2.2039,  1.1804]],\n",
      "\n",
      "        [[ 2.4105, -0.9141,  1.3970,  2.6520],\n",
      "         [-1.8181,  1.1893, -1.4876, -1.0667],\n",
      "         [ 2.3234, -3.2282,  2.5541,  2.1349],\n",
      "         [ 0.7224, -0.2280,  0.5993,  1.2109],\n",
      "         [-0.2501, -0.6181, -0.6317, -1.0200],\n",
      "         [ 2.2070, -1.6409,  1.0768,  0.9574],\n",
      "         [ 2.6526, -2.5386,  0.6066,  1.7098],\n",
      "         [-1.0781,  1.7198,  0.6714,  0.0170]],\n",
      "\n",
      "        [[ 1.6173,  0.5057, -1.0836,  0.4416],\n",
      "         [-3.0435,  3.2857, -0.8178, -0.8080],\n",
      "         [ 1.9775, -0.9438,  0.7398,  1.7809],\n",
      "         [ 1.6705,  0.1167,  1.0265,  2.0492],\n",
      "         [-1.0189,  0.0206,  0.6593, -0.4379],\n",
      "         [-1.1810,  0.2168, -0.7405,  0.7764],\n",
      "         [ 1.2115, -0.7733,  0.6423,  0.1910],\n",
      "         [ 3.3496, -1.8941,  1.7563,  1.0154]],\n",
      "\n",
      "        [[ 1.5215, -0.6775, -0.6219,  0.3339],\n",
      "         [-1.8833,  1.8512,  0.6559,  0.8544],\n",
      "         [ 0.1539, -0.6998,  0.2846, -0.7105],\n",
      "         [ 2.2198, -0.8427, -0.5304,  2.4284],\n",
      "         [-0.4590,  0.6067, -0.7688, -0.3808],\n",
      "         [ 3.5436, -2.8923,  0.6832,  1.3148],\n",
      "         [ 3.7280, -2.5810,  1.7485,  1.1458],\n",
      "         [ 1.1673, -1.6454,  0.7044,  1.0410]]], grad_fn=<UnsafeViewBackward0>)\n",
      "V矩阵torch.Size([4, 8, 4])：\n",
      " tensor([[[ 0.8330, -0.6322, -0.3649,  0.3092],\n",
      "         [-1.7606,  0.9843,  0.8431,  0.6406],\n",
      "         [-0.3775,  0.4470,  0.3364, -0.3987],\n",
      "         [-2.6975,  1.9019,  2.2533,  1.0320],\n",
      "         [-1.9954,  0.5231, -0.3200, -0.4208],\n",
      "         [ 2.1267, -0.8093,  0.2470,  2.5975],\n",
      "         [ 0.8923, -1.9152, -1.3089,  0.8578],\n",
      "         [ 0.2344, -0.8843, -0.4881,  1.7234]],\n",
      "\n",
      "        [[-0.5682, -0.0516,  0.5027,  1.8076],\n",
      "         [ 0.2513,  0.4984,  0.3270, -0.9851],\n",
      "         [-2.3842,  0.1579, -0.1050,  1.5742],\n",
      "         [-0.3506,  0.1801,  0.4446,  1.0571],\n",
      "         [-0.2818, -0.1509, -0.6615, -1.6644],\n",
      "         [-0.4364, -0.6325, -0.6596, -0.0100],\n",
      "         [-1.5824, -0.1883, -0.4855, -0.7900],\n",
      "         [ 1.0668,  0.1556,  0.7834,  2.2780]],\n",
      "\n",
      "        [[ 1.1739, -0.7843, -0.4508, -1.4459],\n",
      "         [ 1.4355,  0.7867,  1.4003,  1.7302],\n",
      "         [-0.4927, -0.1520,  0.1126,  0.6274],\n",
      "         [ 0.2346, -0.1261,  0.5924,  1.8881],\n",
      "         [-0.3044,  0.3166,  0.2181,  0.9712],\n",
      "         [-1.2741,  1.2689,  1.1539,  0.2783],\n",
      "         [ 0.1094, -0.5782, -0.5758, -0.0913],\n",
      "         [ 0.2347, -1.3855, -1.2242,  0.1829]],\n",
      "\n",
      "        [[ 0.0832, -0.5352, -0.6285, -1.5946],\n",
      "         [ 0.0860,  1.1251,  1.7833,  3.2460],\n",
      "         [-0.0827, -0.3583, -0.6569, -0.5934],\n",
      "         [-0.8821,  0.2202,  0.4424, -0.5184],\n",
      "         [ 0.3608,  0.0403,  0.0434, -0.6178],\n",
      "         [-1.0288, -0.9139, -1.2524, -1.5596],\n",
      "         [-0.2631, -1.3753, -1.4147, -0.3019],\n",
      "         [-1.3183,  0.1555, -0.0811,  0.0643]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "W_q = nn.Linear(d_model, d_model, bias=False) # Wq矩阵\n",
    "W_k = nn.Linear(d_model, d_model, bias=False) # Wk矩阵\n",
    "W_v = nn.Linear(d_model, d_model, bias=False) # Wv矩阵\n",
    "print(f'W_q矩阵{W_q.weight.shape}：\\n {W_q.weight}') \n",
    "print(f'W_k矩阵{W_k.weight.shape}：\\n {W_k.weight}') \n",
    "print(f'W_v矩阵{W_v.weight.shape}：\\n {W_v.weight}') \n",
    " # 输出的维度是 (batch_size, seq_len, d_model)\n",
    "Q = W_q(x)\n",
    "K = W_k(x)\n",
    "V = W_v(x)\n",
    "print(f'Q矩阵{Q.shape}：\\n {Q}') \n",
    "print(f'K矩阵{K.shape}：\\n {K}') \n",
    "print(f'V矩阵{V.shape}：\\n {V}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e7533-edc9-4b9f-9e27-addf2ad0ae0d",
   "metadata": {},
   "source": [
    "### 1.4 自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80d4bb2c-69a3-4809-98d3-d6e218f3dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V, dropout: nn.Dropout):\n",
    "    d_k = Q.shape[-1]   # 得到词向量维度\n",
    "    # (1)根据论文公式计算注意力分布矩阵\n",
    "    # (batch_size, seq_len, d_k) --> (batch_size, seq_len, seq_len)\n",
    "    attention_matrix = (Q @ K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    attention_matrix = attention_matrix.softmax(dim=-1) #对矩阵最后一个维度做归一化 \n",
    "    if dropout is not None:\n",
    "        attention_matrix = dropout(attention_matrix)\n",
    "    # （2）加权求和\n",
    "    # (batch_size, seq_len, seq_len) --> (batch_size, seq_len, d_v)\n",
    "    X = torch.matmul(attention_matrix, V)\n",
    "    # 返回注意力分布矩阵用于后续的可视化\n",
    "    return X, attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09401ec2-4a52-4c3c-be76-3526221ac882",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自注意力分布矩阵torch.Size([4, 8, 8])：\n",
      " tensor([[[1.2754e-01, 1.7161e-01, 1.8320e-01, 1.9311e-01, 1.4973e-01,\n",
      "          1.3565e-01, 5.8319e-02, 9.1963e-02],\n",
      "         [6.8067e-02, 1.5752e-02, 1.9029e-02, 8.0425e-03, 2.9105e-02,\n",
      "          4.8730e-02, 7.7898e-01, 1.4340e-01],\n",
      "         [1.6402e-01, 0.0000e+00, 1.5378e-01, 1.1436e-01, 1.0149e-01,\n",
      "          2.0378e-01, 1.2857e-01, 1.2787e-01],\n",
      "         [1.3547e-01, 0.0000e+00, 1.6308e-02, 4.0948e-04, 1.8914e-03,\n",
      "          2.6820e-01, 6.3158e-01, 5.5634e-02],\n",
      "         [5.0111e-03, 5.7917e-03, 9.1927e-04, 4.6598e-03, 1.5348e-02,\n",
      "          2.3897e-03, 9.6273e-01, 1.1427e-01],\n",
      "         [7.4134e-02, 1.5589e-01, 0.0000e+00, 1.3638e-01, 1.8234e-01,\n",
      "          3.0691e-02, 0.0000e+00, 5.9186e-03],\n",
      "         [6.1080e-02, 2.6243e-02, 1.7509e-02, 2.2492e-02, 2.6068e-02,\n",
      "          1.0408e-01, 6.3973e-01, 0.0000e+00],\n",
      "         [7.5446e-02, 6.4655e-02, 4.1244e-02, 4.4399e-02, 1.3055e-01,\n",
      "          3.7818e-02, 0.0000e+00, 1.9520e-01]],\n",
      "\n",
      "        [[1.1469e-01, 8.7725e-02, 7.9321e-02, 9.2950e-02, 1.9499e-01,\n",
      "          2.6893e-01, 2.0280e-01, 0.0000e+00],\n",
      "         [5.1485e-02, 4.4512e-01, 0.0000e+00, 1.1061e-01, 1.2023e-01,\n",
      "          3.4184e-02, 2.9694e-02, 2.9773e-01],\n",
      "         [4.4778e-02, 4.0835e-05, 6.5662e-01, 3.7371e-03, 2.6389e-03,\n",
      "          1.5540e-01, 2.4774e-01, 1.5490e-04],\n",
      "         [1.0582e-01, 1.4837e-01, 9.0608e-02, 1.1169e-01, 2.0683e-01,\n",
      "          1.8241e-01, 1.6942e-01, 9.5963e-02],\n",
      "         [2.4119e-01, 1.9416e-02, 3.8885e-01, 0.0000e+00, 2.9690e-02,\n",
      "          1.2283e-01, 1.2158e-01, 7.9942e-02],\n",
      "         [2.0256e-01, 0.0000e+00, 4.0669e-01, 0.0000e+00, 2.5369e-02,\n",
      "          1.9889e-01, 1.8596e-01, 2.4798e-02],\n",
      "         [2.5278e-01, 1.0273e-03, 4.1027e-01, 3.6058e-02, 8.2337e-03,\n",
      "          2.3427e-01, 1.5626e-01, 1.2213e-02],\n",
      "         [6.3994e-03, 7.3698e-01, 5.0440e-03, 3.2084e-02, 2.4457e-01,\n",
      "          1.4410e-02, 2.1274e-02, 5.0350e-02]],\n",
      "\n",
      "        [[2.8566e-02, 9.5769e-01, 9.7493e-03, 3.3523e-02, 2.9420e-02,\n",
      "          0.0000e+00, 9.6996e-03, 2.7697e-03],\n",
      "         [1.0888e-02, 9.4063e-01, 7.3165e-04, 6.7889e-04, 1.7188e-02,\n",
      "          1.3923e-01, 1.7302e-03, 4.3461e-05],\n",
      "         [2.0436e-01, 3.5254e-02, 1.2723e-01, 1.3013e-01, 5.6360e-02,\n",
      "          2.6992e-02, 1.5221e-01, 3.7859e-01],\n",
      "         [3.6426e-01, 2.3237e-01, 6.7382e-02, 6.2203e-02, 9.1017e-02,\n",
      "          8.8301e-02, 0.0000e+00, 8.2880e-02],\n",
      "         [1.0834e-01, 2.7760e-02, 0.0000e+00, 8.8625e-02, 1.3452e-01,\n",
      "          1.4596e-01, 1.8232e-01, 2.4752e-01],\n",
      "         [3.0962e-01, 1.1188e-01, 1.0527e-01, 9.3042e-02, 9.0477e-02,\n",
      "          7.3242e-02, 1.5546e-01, 1.7212e-01],\n",
      "         [8.7773e-02, 3.7711e-02, 1.8369e-01, 1.7980e-01, 9.8411e-02,\n",
      "          6.6842e-02, 1.4699e-01, 3.0990e-01],\n",
      "         [3.9317e-02, 4.1391e-03, 1.5437e-01, 1.4574e-01, 3.4494e-02,\n",
      "          1.2746e-02, 1.0413e-01, 6.1617e-01]],\n",
      "\n",
      "        [[8.5871e-02, 0.0000e+00, 8.8179e-02, 1.2037e-01, 1.0518e-01,\n",
      "          7.3883e-02, 1.5503e-01, 9.3088e-02],\n",
      "         [2.6622e-01, 3.2087e-02, 1.9911e-01, 7.4256e-02, 4.2089e-01,\n",
      "          4.9904e-02, 0.0000e+00, 5.5939e-02],\n",
      "         [0.0000e+00, 6.4237e-02, 7.9713e-02, 1.1491e-01, 4.0349e-02,\n",
      "          2.4782e-01, 3.2130e-01, 1.7418e-01],\n",
      "         [1.9661e-01, 1.1591e-01, 1.1822e-01, 1.0687e-01, 1.6522e-01,\n",
      "          1.0865e-01, 2.4918e-01, 5.0445e-02],\n",
      "         [9.9157e-02, 4.3547e-01, 1.1143e-01, 1.0643e-01, 2.0699e-01,\n",
      "          3.5032e-02, 3.2767e-02, 8.3837e-02],\n",
      "         [1.1669e-02, 3.5205e-03, 9.2126e-03, 1.9801e-02, 2.1588e-03,\n",
      "          0.0000e+00, 8.5994e-01, 2.5221e-02],\n",
      "         [1.6081e-02, 3.4236e-03, 1.4135e-02, 2.6113e-02, 3.1367e-03,\n",
      "          0.0000e+00, 7.5406e-01, 4.1718e-02],\n",
      "         [3.9109e-02, 0.0000e+00, 2.8127e-02, 3.6585e-02, 8.3352e-03,\n",
      "          3.2660e-01, 6.2151e-01, 4.7852e-02]]], grad_fn=<MulBackward0>)\n",
      "自注意力计算结果torch.Size([4, 8, 4])：\n",
      " tensor([[[-0.7226,  0.3130,  0.4593,  0.7735],\n",
      "         [ 0.7744, -1.6466, -1.0739,  1.0615],\n",
      "         [ 0.1457, -0.2886,  0.0367,  0.9247],\n",
      "         [ 1.2488, -1.5524, -0.8312,  1.3693],\n",
      "         [ 0.8414, -1.9269, -1.3063,  1.0322],\n",
      "         [-0.8778,  0.4313,  0.3580,  0.2767],\n",
      "         [ 0.6776, -1.2580, -0.7636,  0.8600],\n",
      "         [-0.3206, -0.0161,  0.0132,  0.4738]],\n",
      "\n",
      "        [[-0.7580, -0.1706, -0.2855, -0.1434],\n",
      "         [ 0.2657,  0.2401,  0.3373,  0.2258],\n",
      "         [-2.0527, -0.0432, -0.2692,  0.9172],\n",
      "         [-0.5816, -0.0606, -0.1224,  0.0445],\n",
      "         [-1.2283, -0.0340, -0.0103,  1.0644],\n",
      "         [-1.4465, -0.1070, -0.1597,  0.8717],\n",
      "         [-1.4730, -0.1182, -0.1259,  1.0282],\n",
      "         [ 0.1031,  0.3314,  0.1157, -0.9819]],\n",
      "\n",
      "        [[ 1.4041,  0.7252,  1.3466,  1.7133],\n",
      "         [ 1.1804,  0.9123,  1.4761,  1.6688],\n",
      "         [ 0.3123, -0.7288, -0.4590,  0.2087],\n",
      "         [ 0.6218, -0.0949,  0.2259,  0.1632],\n",
      "         [ 0.0389, -0.2949, -0.1677,  0.2586],\n",
      "         [ 0.4305, -0.3893, -0.1119,  0.1132],\n",
      "         [ 0.0825, -0.4882, -0.2250,  0.5505],\n",
      "         [ 0.1395, -0.9563, -0.7003,  0.4626]],\n",
      "\n",
      "        [[-0.3079, -0.3131, -0.3735, -0.4727],\n",
      "         [-0.0303, -0.1813, -0.2568, -0.8113],\n",
      "         [-0.6570, -0.5706, -0.6643, -0.3956],\n",
      "         [-0.2619, -0.4211, -0.4328, -0.4063],\n",
      "         [-0.1379,  0.3647,  0.6001,  0.9471],\n",
      "         [-0.2757, -1.1799, -1.2169, -0.2822],\n",
      "         [-0.2748, -1.0345, -1.0718, -0.2634],\n",
      "         [-0.5909, -1.1684, -1.3187, -0.7971]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "dropout_layer = nn.Dropout(p = 0.1)\n",
    "X, attention_matrix = attention(Q, K, V, dropout_layer)\n",
    "print(f'自注意力分布矩阵{attention_matrix.shape}：\\n {attention_matrix}') \n",
    "print(f'自注意力计算结果{X.shape}：\\n {X}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173473a-4043-4c53-814d-7ec0c66db593",
   "metadata": {},
   "source": [
    "### 1.5 交叉注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fdf351-3459-4931-8f74-110bffe107d1",
   "metadata": {},
   "source": [
    "程序段1.5：交叉注意力计算逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feb9e285-cbc9-4dea-956a-a0d11e6118c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉注意力分布矩阵torch.Size([4, 8, 8])：\n",
      " tensor([[[1.5774e-01, 4.4293e-02, 3.0673e-01, 1.3085e-01, 4.6552e-02,\n",
      "          2.9525e-01, 9.9089e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 1.0799e+00, 2.0402e-03, 1.5450e-04, 1.9553e-02,\n",
      "          2.5313e-04, 5.2604e-03, 1.3821e-03],\n",
      "         [1.0317e-01, 0.0000e+00, 9.1092e-02, 7.1809e-02, 2.2481e-01,\n",
      "          5.8494e-02, 1.5557e-01, 1.5196e-01],\n",
      "         [4.8893e-02, 0.0000e+00, 4.9056e-02, 1.3419e-01, 2.5282e-01,\n",
      "          3.6709e-02, 2.1352e-01, 3.7255e-01],\n",
      "         [3.0923e-02, 9.9031e-01, 3.9583e-02, 5.0485e-03, 8.1219e-03,\n",
      "          2.6019e-02, 9.0277e-03, 2.0823e-03],\n",
      "         [0.0000e+00, 1.0285e+00, 1.1949e-02, 5.5123e-03, 1.7375e-02,\n",
      "          9.8177e-03, 9.5383e-03, 9.6989e-03],\n",
      "         [5.3914e-03, 1.0879e+00, 2.6269e-03, 1.2270e-03, 6.0681e-03,\n",
      "          2.1552e-03, 2.4521e-03, 3.3031e-03],\n",
      "         [9.2723e-02, 1.1099e-02, 1.2354e-01, 1.4503e-01, 2.1857e-01,\n",
      "          8.2328e-02, 2.4435e-01, 1.9347e-01]],\n",
      "\n",
      "        [[5.5223e-03, 2.2540e-01, 3.2292e-02, 4.7455e-01, 1.3602e-01,\n",
      "          0.0000e+00, 2.1704e-02, 2.1315e-01],\n",
      "         [3.6094e-02, 0.0000e+00, 8.9229e-02, 2.8063e-01, 3.1415e-01,\n",
      "          1.1159e-02, 0.0000e+00, 1.0517e-01],\n",
      "         [0.0000e+00, 2.2218e-02, 1.6258e-01, 5.3525e-03, 3.8078e-02,\n",
      "          5.0193e-01, 1.0917e-01, 0.0000e+00],\n",
      "         [2.3138e-01, 4.9268e-02, 1.0857e-01, 0.0000e+00, 6.0242e-01,\n",
      "          1.7715e-02, 6.5993e-02, 5.0805e-03],\n",
      "         [1.1253e-01, 1.3518e-01, 1.8831e-01, 7.4972e-02, 0.0000e+00,\n",
      "          2.7146e-02, 8.9018e-02, 2.7442e-02],\n",
      "         [2.8778e-02, 9.1166e-02, 5.3725e-01, 4.8861e-03, 0.0000e+00,\n",
      "          9.3903e-03, 3.8559e-02, 3.0112e-03],\n",
      "         [2.6562e-02, 3.0848e-02, 2.3795e-03, 7.8058e-01, 2.5830e-02,\n",
      "          8.6815e-03, 2.0486e-02, 2.1575e-01],\n",
      "         [0.0000e+00, 9.1959e-02, 1.9185e-01, 2.7872e-02, 6.5966e-01,\n",
      "          8.6152e-03, 5.0358e-02, 6.5110e-03]],\n",
      "\n",
      "        [[4.6594e-01, 2.4470e-02, 2.1041e-03, 1.0389e-01, 2.8867e-04,\n",
      "          4.1406e-01, 9.8704e-02, 1.6531e-03],\n",
      "         [8.2950e-03, 5.3180e-02, 1.1215e-01, 0.0000e+00, 0.0000e+00,\n",
      "          8.2676e-03, 1.8854e-02, 7.9932e-02],\n",
      "         [7.7883e-02, 1.5144e-01, 1.4545e-01, 1.1896e-01, 2.3490e-01,\n",
      "          1.3168e-01, 1.2496e-01, 1.2584e-01],\n",
      "         [3.9366e-01, 1.1586e-01, 5.3634e-02, 1.5229e-01, 4.2855e-02,\n",
      "          1.5995e-01, 1.4799e-01, 4.4865e-02],\n",
      "         [3.4151e-02, 0.0000e+00, 1.4582e-01, 7.4971e-02, 4.6063e-01,\n",
      "          7.2920e-02, 8.1006e-02, 1.0655e-01],\n",
      "         [4.4385e-02, 0.0000e+00, 2.5607e-01, 2.7904e-02, 1.8373e-01,\n",
      "          6.4700e-03, 2.3837e-02, 5.3562e-01],\n",
      "         [3.3009e-02, 9.0571e-02, 2.3888e-02, 1.2277e-01, 1.8285e-02,\n",
      "          6.6148e-01, 1.4409e-01, 1.7021e-02],\n",
      "         [6.2471e-03, 1.4664e-01, 9.6814e-02, 6.8727e-02, 0.0000e+00,\n",
      "          1.9330e-01, 8.6121e-02, 0.0000e+00]],\n",
      "\n",
      "        [[2.2690e-02, 5.6277e-01, 2.9503e-01, 1.2193e-01, 8.1147e-03,\n",
      "          6.5722e-02, 9.2649e-03, 0.0000e+00],\n",
      "         [5.2699e-03, 1.9193e-02, 2.4638e-02, 1.6131e-01, 0.0000e+00,\n",
      "          0.0000e+00, 3.0926e-01, 4.5031e-02],\n",
      "         [1.0841e+00, 0.0000e+00, 1.6152e-02, 6.2399e-04, 4.5642e-06,\n",
      "          8.6354e-07, 6.0776e-05, 1.4530e-04],\n",
      "         [1.3612e-04, 9.7515e-02, 9.1239e-02, 9.1963e-01, 1.0170e-05,\n",
      "          7.9508e-04, 0.0000e+00, 1.2283e-05],\n",
      "         [4.1743e-06, 0.0000e+00, 7.7640e-04, 3.3488e-01, 4.0426e-02,\n",
      "          2.3377e-01, 5.0044e-01, 4.4734e-04],\n",
      "         [9.9037e-02, 9.9928e-02, 0.0000e+00, 3.2896e-02, 2.2933e-01,\n",
      "          2.1348e-01, 5.7105e-02, 3.0607e-01],\n",
      "         [1.2426e-03, 8.7222e-02, 7.2601e-02, 5.2333e-01, 2.9187e-02,\n",
      "          2.9431e-01, 9.3265e-02, 9.9498e-03],\n",
      "         [4.1335e-05, 2.0608e-03, 2.1415e-03, 7.6886e-02, 1.4697e-01,\n",
      "          7.1720e-01, 1.5828e-01, 7.5299e-03]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "交叉注意力计算结果torch.Size([4, 8, 4])：\n",
      " tensor([[[-1.0159e+00,  3.4550e-01,  1.7205e-01, -4.5133e-02],\n",
      "         [ 4.7513e-01, -2.8431e+00, -2.4089e+00,  1.3186e+00],\n",
      "         [ 5.4423e-01, -4.6303e-01, -3.5822e-01, -3.3915e-04],\n",
      "         [ 1.2146e+00, -7.5185e-01, -3.9647e-01,  3.5183e-01],\n",
      "         [ 2.9343e-01, -2.5434e+00, -2.1743e+00,  1.1976e+00],\n",
      "         [ 4.3488e-01, -2.6961e+00, -2.2810e+00,  1.2661e+00],\n",
      "         [ 4.4404e-01, -2.8377e+00, -2.4012e+00,  1.3426e+00],\n",
      "         [ 5.7085e-01, -4.8143e-01, -3.4498e-01,  5.8584e-02]],\n",
      "\n",
      "        [[-7.3545e-01, -1.5736e-01,  8.4496e-02,  1.6447e+00],\n",
      "         [ 5.0159e-01, -5.7643e-01, -1.0765e-01,  1.3450e+00],\n",
      "         [-3.5581e-01,  3.6216e-01,  3.9338e-01,  4.3789e-01],\n",
      "         [ 2.5057e+00, -1.4091e+00, -3.0480e-01,  1.8935e+00],\n",
      "         [ 4.0399e-01, -1.8409e-01,  2.2387e-01,  1.0140e+00],\n",
      "         [ 1.5136e+00, -3.9224e-01,  5.5937e-01,  2.0615e+00],\n",
      "         [-2.0044e+00,  1.8770e-01, -3.8083e-02,  7.5427e-01],\n",
      "         [ 2.8671e+00, -1.4804e+00, -1.1189e-01,  2.7368e+00]],\n",
      "\n",
      "        [[-3.2089e-02, -8.1898e-01, -9.2198e-01, -3.9758e-01],\n",
      "         [-7.1868e-02,  9.7609e-02,  1.2203e-01,  1.8567e-01],\n",
      "         [-6.4826e-01,  2.9503e-01,  1.8365e-01,  6.8771e-02],\n",
      "         [ 5.7374e-02, -5.9075e-01, -6.5085e-01, -2.4424e-01],\n",
      "         [-7.9587e-01,  6.9220e-01,  6.0357e-01,  1.2027e-02],\n",
      "         [-2.4798e-01,  6.3992e-01,  8.6211e-01,  8.4724e-01],\n",
      "         [-1.1073e+00, -1.5397e-01, -4.7786e-01, -1.0161e-01],\n",
      "         [-4.6580e-01, -1.2335e-02, -1.5494e-01,  1.2982e-02]],\n",
      "\n",
      "        [[-6.5850e-01,  9.6348e-01,  1.2151e+00,  1.2054e+00],\n",
      "         [ 8.2369e-01, -6.6790e-01, -4.8566e-01,  8.8170e-02],\n",
      "         [-5.8930e+00,  2.4489e+00, -1.4404e-01, -4.9633e+00],\n",
      "         [ 3.1309e+00, -1.1799e+00,  9.0125e-02,  1.3351e+00],\n",
      "         [ 1.8136e+00, -1.3697e+00, -6.5147e-01,  9.2279e-01],\n",
      "         [-2.6346e+00,  8.3981e-01,  3.3272e-01,  2.9820e-01],\n",
      "         [ 1.5763e+00, -6.9261e-01,  3.0476e-01,  1.6494e+00],\n",
      "         [-2.9771e-01, -2.2953e-01,  5.0558e-01,  2.1963e+00]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Q 矩阵来源自于序列 X1，键矩阵 K 和值矩阵 V 源自序列 X2\n",
    "X1 = torch.randint(0, vocab_size, (batch_size, seq_len)) # 模拟序列 X1\n",
    "X2 = torch.randint(0, vocab_size, (batch_size, seq_len)) # 模拟序列 X2\n",
    "input_embedding = InputEmbeddings(vocab_size, d_model)  # 词向量编码\n",
    "X1 = input_embedding(X1)\n",
    "X2 = input_embedding(X2)\n",
    "position_encoding = PositionalEncoding(seq_len, d_model, dropout)\n",
    "X1, positon_encode = position_encoding(X1)\n",
    "X2, positon_encode = position_encoding(X2)\n",
    "\n",
    " # 源自不同的序列，输出的维度是 (batch_size, seq_len, d_model)\n",
    "Q = W_q(X1)\n",
    "K = W_k(X2)\n",
    "V = W_v(X2)\n",
    "\n",
    "dropout_layer = nn.Dropout(p = 0.1)\n",
    "X, attention_matrix = attention(Q, K, V, dropout_layer)\n",
    "print(f'交叉注意力分布矩阵{attention_matrix.shape}：\\n {attention_matrix}') \n",
    "print(f'\\n交叉注意力计算结果{X.shape}：\\n {X}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f214e-2b93-4ca7-a958-a82a6e4661ae",
   "metadata": {},
   "source": [
    "### 1.6 掩码注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc1872-c370-44a1-ae7e-dbff6640336f",
   "metadata": {},
   "source": [
    "程序段1.6实现了掩码注意力的计算逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5917d414-45d5-48c5-8fbe-46963cf9e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V, mask, dropout: nn.Dropout):\n",
    "    d_k = Q.shape[-1]   # 得到词向量维度\n",
    "    # (1)根据论文公式计算注意力分布矩阵\n",
    "    # (batch_size, seq_len, d_k) --> (batch_size, seq_len, seq_len)\n",
    "    attention_matrix = (Q @ K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        # 掩码操作，将 mask 为 0 的元素设置为 一个极小的数\n",
    "        attention_matrix.masked_fill_(mask == 0, -1e9)\n",
    "    attention_matrix = attention_matrix.softmax(dim=-1) #对矩阵最后一个维度做归一化 \n",
    "    if dropout is not None:\n",
    "        attention_matrix = dropout(attention_matrix)\n",
    "    # （2）加权求和\n",
    "    # (batch_size, seq_len, seq_len) --> (batch_size, seq_len, d_v)\n",
    "    X = torch.matmul(attention_matrix, V)\n",
    "    # 返回注意力分布矩阵用于后续的可视化\n",
    "    return X, attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95237bba-3042-45b0-9555-183e1e2168b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "掩码注意力分布矩阵torch.Size([4, 8, 8])：\n",
      " tensor([[[1.1111e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.6720e-03, 1.1084e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.5561e-01, 6.2981e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.3067e-01, 0.0000e+00, 2.3144e-01, 6.3306e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.1992e-02, 1.0245e+00, 4.0952e-02, 5.2230e-03, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.9086e-02, 1.0466e+00, 1.2159e-02, 5.6094e-03, 1.7682e-02,\n",
      "          9.9907e-03, 0.0000e+00, 0.0000e+00],\n",
      "         [5.4074e-03, 1.0911e+00, 2.6347e-03, 1.2306e-03, 6.0861e-03,\n",
      "          2.1616e-03, 2.4595e-03, 0.0000e+00],\n",
      "         [9.2723e-02, 1.1099e-02, 1.2354e-01, 1.4503e-01, 2.1857e-01,\n",
      "          8.2328e-02, 2.4435e-01, 1.9347e-01]],\n",
      "\n",
      "        [[1.1111e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [6.4976e-01, 5.5469e-02, 4.0588e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [6.1227e-01, 1.3037e-01, 2.8729e-01, 8.1188e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.2923e-01, 0.0000e+00, 2.1626e-01, 8.6101e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 9.4710e-02, 5.5813e-01, 5.0760e-03, 4.1354e-01,\n",
      "          9.7553e-03, 0.0000e+00, 0.0000e+00],\n",
      "         [3.2962e-02, 3.8281e-02, 2.9528e-03, 9.6867e-01, 3.2053e-02,\n",
      "          1.0773e-02, 2.5423e-02, 0.0000e+00],\n",
      "         [7.4282e-02, 9.1959e-02, 1.9185e-01, 0.0000e+00, 6.5966e-01,\n",
      "          8.6152e-03, 5.0358e-02, 6.5110e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.4992e-01, 9.6119e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 4.4899e-01, 4.3122e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [6.1137e-01, 1.7994e-01, 8.3295e-02, 2.3651e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.4608e-02, 1.7643e-01, 1.9047e-01, 9.7928e-02, 6.0168e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [8.9398e-02, 6.6662e-02, 5.1577e-01, 0.0000e+00, 3.7005e-01,\n",
      "          1.3032e-02, 0.0000e+00, 0.0000e+00],\n",
      "         [3.3522e-02, 9.1980e-02, 0.0000e+00, 1.2468e-01, 1.8570e-02,\n",
      "          6.7177e-01, 1.4633e-01, 0.0000e+00],\n",
      "         [6.2471e-03, 1.4664e-01, 9.6814e-02, 6.8727e-02, 4.5948e-01,\n",
      "          1.9330e-01, 8.6121e-02, 5.3780e-02]],\n",
      "\n",
      "        [[1.1111e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.3935e-01, 8.7176e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0849e+00, 1.0060e-02, 1.6164e-02, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.3643e-04, 9.7742e-02, 9.1452e-02, 9.2178e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.2321e-05, 1.0768e-03, 2.2916e-03, 9.8841e-01, 1.1932e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.4713e-01, 1.4845e-01, 1.0886e-01, 0.0000e+00, 3.4068e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.2538e-03, 8.8010e-02, 7.3257e-02, 5.2806e-01, 2.9451e-02,\n",
      "          2.9697e-01, 9.4107e-02, 0.0000e+00],\n",
      "         [4.1335e-05, 2.0608e-03, 0.0000e+00, 7.6886e-02, 1.4697e-01,\n",
      "          7.1720e-01, 1.5828e-01, 7.5299e-03]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "掩码注意力计算结果torch.Size([4, 8, 4])：\n",
      " tensor([[[-7.4723e-01, -1.7769e-02, -1.2987e-01,  6.4214e-02],\n",
      "         [ 4.4172e-01, -2.8809e+00, -2.4381e+00,  1.3682e+00],\n",
      "         [ 8.0105e-02, -1.6410e+00, -1.4150e+00,  7.9211e-01],\n",
      "         [-7.9428e-01,  6.0330e-01,  6.5484e-01,  5.1679e-01],\n",
      "         [ 3.3224e-01, -2.6448e+00, -2.2637e+00,  1.2378e+00],\n",
      "         [ 4.0104e-01, -2.7274e+00, -2.3143e+00,  1.2838e+00],\n",
      "         [ 4.3843e-01, -2.8430e+00, -2.4082e+00,  1.3417e+00],\n",
      "         [ 5.7085e-01, -4.8143e-01, -3.4498e-01,  5.8584e-02]],\n",
      "\n",
      "        [[ 3.2810e-01, -5.9561e-01, -6.4486e-01, -1.3056e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3416e+00, -6.3633e-01,  3.8675e-02,  7.6032e-01],\n",
      "         [ 9.3039e-01, -5.6887e-01, -2.3534e-02,  6.7063e-01],\n",
      "         [ 4.5680e-01, -2.0524e-01,  1.1881e-01,  6.0550e-01],\n",
      "         [ 3.0414e+00, -1.2274e+00,  3.5869e-01,  3.2563e+00],\n",
      "         [-1.7002e+00, -4.2382e-02, -1.3489e-01,  5.8330e-01],\n",
      "         [ 2.9423e+00, -1.5216e+00, -1.5115e-01,  2.6380e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-6.0127e-01, -5.8803e-02, -2.7780e-01, -4.9742e-01],\n",
      "         [-4.5911e-01,  2.9834e-01,  2.0468e-01,  2.2989e-01],\n",
      "         [ 6.6250e-01, -9.7372e-01, -9.4723e-01, -3.8372e-01],\n",
      "         [-1.0020e+00,  8.8571e-01,  7.1603e-01, -2.2302e-01],\n",
      "         [-5.8067e-01,  6.7773e-01,  6.3606e-01,  1.9134e-01],\n",
      "         [-1.1209e+00, -1.7939e-01, -5.1773e-01, -1.4986e-01],\n",
      "         [-1.1269e+00,  6.9030e-01,  4.8555e-01, -1.6457e-01]],\n",
      "\n",
      "        [[-6.0350e+00,  2.4994e+00, -1.5652e-01, -5.1023e+00],\n",
      "         [-2.5544e+00,  1.9278e+00,  1.5410e+00, -1.1425e-03],\n",
      "         [-5.9136e+00,  2.4676e+00, -1.2585e-01, -4.9550e+00],\n",
      "         [ 3.1388e+00, -1.1828e+00,  8.9360e-02,  1.3359e+00],\n",
      "         [ 3.2720e+00, -1.4955e+00, -2.2279e-01,  1.2553e+00],\n",
      "         [-1.8628e+00,  6.5581e-01,  8.0937e-02, -2.8883e-01],\n",
      "         [ 1.6394e+00, -7.1717e-01,  3.0227e-01,  1.6673e+00],\n",
      "         [-2.9685e-01, -2.3101e-01,  5.0442e-01,  2.1944e+00]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "dropout_layer = nn.Dropout(p = 0.1)\n",
    "# 构建一个下三角矩阵，屏蔽未来位置\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0)\n",
    "X, attention_matrix = attention(Q, K, V, mask, dropout_layer)\n",
    "print(f'掩码注意力分布矩阵{attention_matrix.shape}：\\n {attention_matrix}') \n",
    "print(f'\\n掩码注意力计算结果{X.shape}：\\n {X}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd781c-c500-4514-9d09-4d822c933949",
   "metadata": {},
   "source": [
    "### 1.7 多头注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd61578-5776-4a48-9722-0bbc7c3abf1f",
   "metadata": {},
   "source": [
    "程序段1.7实现了多头注意力的计算逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d9afac6-2368-4070-99df-2250a0494bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多头注意力模块，带掩码设置，也可计算交叉注意力\n",
    "class MultiHeadAttention(nn.Module):  \n",
    "\n",
    "    def __init__(self, d_model: int, heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model   # 模型维度\n",
    "        self.heads = heads  # 头数\n",
    "        # 需要确定 d_model 能被 heads 整除\n",
    "        assert d_model % heads == 0, \"d_model 不能被 heads 整除\"\n",
    "\n",
    "        self.d_k = d_model // heads  # 计算单个头的词向量长度\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False) # Wq矩阵\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False) # Wk矩阵\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False) # Wv矩阵\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False) # Wo矩阵\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(Q, K, V, mask, dropout: nn.Dropout):\n",
    "        d_k = Q.shape[-1]   # 词向量长度\n",
    "        # （1）根据论文公式计算注意力\n",
    "        # (batch_size, heads, seq_len, d_k) --> (batch_size, heads, seq_len, seq_len)\n",
    "        attention_matrix = (Q @ K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            # 掩码操作，根据 mask 矩阵，将 attention_matrix 掩码位置设为一个极小的数\n",
    "            attention_matrix.masked_fill_(mask == 0, -1e9)\n",
    "        # 在 (batch_size, heads, seq_len, seq_len) 最后一个维度上归一化 \n",
    "        attention_matrix = attention_matrix.softmax(dim=-1) \n",
    "        if dropout is not None:\n",
    "            attention_matrix = dropout(attention_matrix)\n",
    "        # （2）加权求和\n",
    "        # (batch_size, seq_len, seq_len) --> (batch_size, seq_len, d_v)\n",
    "        X = torch.matmul(attention_matrix, V)\n",
    "        # 返回注意力分数矩阵用于后续的可视化\n",
    "        return X, attention_matrix\n",
    "        \n",
    "    # Query, Key, Value 表示来自上一层的输入\n",
    "    def forward(self, Query, Key, Value, mask):\n",
    "        # （1）上一层的输入映射为 Q、K、V 矩阵\n",
    "        Q = self.W_q(Query)  \n",
    "        K = self.W_k(Key)  \n",
    "        V = self.W_v(Value)  \n",
    "        # （2）分头操作，调整矩阵维度\n",
    "        # (batch_size, seq_len, d_model) --> (batch_size, seq_len, heads, d_k) \n",
    "        # --> (batch_size, heads, seq_len, d_k)\n",
    "        Q = Q.view(Q.shape[0], Q.shape[1], self.heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(K.shape[0], K.shape[1], self.heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(V.shape[0], V.shape[1], self.heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # （3）计算注意力，注意 Q、K、V 的矩阵维度此时是分头状态\n",
    "        X, self.attention_matrix = MultiHeadAttention.attention(Q, K, V, mask, self.dropout)\n",
    "        \n",
    "        # （4）合并单头注意力，调整 Q、K、V 的矩阵维度\n",
    "        # (batch_size, heads, seq_len, d_k) --> (batch_size, seq_len, heads, d_k) \n",
    "        # --> (batch_size, seq_len, d_model)\n",
    "        X = X.transpose(1, 2).contiguous().view(X.shape[0], -1, self.heads * self.d_k)\n",
    "\n",
    "        # （5）多头注意力的最后一层是线性层，用 Wo 矩阵表示\n",
    "        X = self.W_o(X)\n",
    "        X = self.dropout(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6bbfb6-24ae-45d8-bb47-6282d56da74e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多头注意力计算结果torch.Size([4, 8, 512])：\n",
      " tensor([[[ -7.3791,   2.1448,   0.7829,  ...,   6.9030,   9.3861,   0.0000],\n",
      "         [  2.5428,  -5.7630,   0.0000,  ...,  -1.1007, -13.4121,   5.6321],\n",
      "         [-13.7783,   1.8668, -11.1591,  ...,  -8.8603,  -7.9482, -14.5927],\n",
      "         ...,\n",
      "         [ -5.5646,   4.3508,  -5.0623,  ...,   3.9187,  -1.9886,  -4.7542],\n",
      "         [  3.5289,   2.2999,   5.4827,  ..., -10.9634,  -9.4228,  -3.6248],\n",
      "         [ 11.2869,   9.8718,  -4.5895,  ...,   4.5762,  -7.1419,  -3.2897]],\n",
      "\n",
      "        [[  5.2099,  13.9342,   1.2197,  ..., -14.3893,  18.5205,  -5.3147],\n",
      "         [  8.7584,  -3.1686,   0.0000,  ..., -10.5332,   9.2925,  10.2795],\n",
      "         [  2.5875,   7.0298,   4.4812,  ...,  -7.1233,   6.6587,   5.7045],\n",
      "         ...,\n",
      "         [  2.9565,   4.6786,   6.4331,  ...,   5.4211, -13.6371,   6.2226],\n",
      "         [ 11.8787,   4.6417,  -0.0000,  ...,  11.8295,   3.2298,  -9.1687],\n",
      "         [-13.2332,  12.3829, -20.7847,  ..., -10.4894,  13.8055,  19.5107]],\n",
      "\n",
      "        [[-15.7769,   0.0000,  11.1875,  ...,  -6.2981,  -3.5375,   1.0772],\n",
      "         [ -3.0078,   9.9508,  11.1900,  ...,  -9.0136,   3.0220,  12.0540],\n",
      "         [ 11.6623,   0.0000,   3.5723,  ...,  -4.1414,  -8.7376,  17.6145],\n",
      "         ...,\n",
      "         [  8.2062,   3.7300,  -1.1794,  ...,   7.5920,  -3.1807,   5.4067],\n",
      "         [  0.0000,   3.1008,   1.9525,  ...,  -0.6346, -10.5837,   2.0074],\n",
      "         [ -2.7631,  11.2192,   8.0144,  ...,  -8.7495, -12.6657,   5.1281]],\n",
      "\n",
      "        [[ 11.1633, -10.2949,   6.9224,  ..., -11.3412,  -9.4075, -12.3999],\n",
      "         [  9.3046,   1.0112,  -3.6027,  ...,  -0.0000, -20.0191,  -7.6482],\n",
      "         [ 12.3958,  -7.3361, -16.3926,  ...,   1.4754, -17.2759,  -2.9700],\n",
      "         ...,\n",
      "         [  6.7461,  15.8179,   7.2919,  ..., -15.3684, -11.1070, -17.8107],\n",
      "         [  9.0796,   2.0373,  -0.6710,  ...,  -0.0000,  -9.8612,   8.1702],\n",
      "         [  2.2803,  -1.5478,  -7.7647,  ...,  -0.0000,  -6.4596,   3.2217]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "vocab_size = 2118  # 设置词典大小\n",
    "batch_size = 4    # 设置批次大小\n",
    "seq_len = 8       # 设置序列最大长度\n",
    "d_model = 512     # 模型维度\n",
    "heads = 8  # 头数\n",
    "dropout = 0.1\n",
    "# 构建一个下三角矩阵，屏蔽未来位置，用作掩码矩阵\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0)\n",
    "\n",
    "# 使用 torch.randint 生成随机整数张量 X，取值范围为 [0, vocab_size),表示输入的序列\n",
    "X = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "# 词向量编码\n",
    "input_embedding = InputEmbeddings(vocab_size, d_model)\n",
    "X = input_embedding(X)\n",
    "\n",
    "# 位置编码叠加词向量编码\n",
    "position_encoding = PositionalEncoding(seq_len, d_model, dropout)\n",
    "X, positon_encode = position_encoding(X)\n",
    "\n",
    "# 多头注意力编码\n",
    "mh_attention_block = MultiHeadAttention(d_model, heads, dropout)\n",
    "X = mh_attention_block(X,X,X,mask)\n",
    "\n",
    "print(f'多头注意力计算结果{X.shape}：\\n {X}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1ed6e-ab52-41cd-ab4b-74164eb75ec8",
   "metadata": {},
   "source": [
    "### 1.8 层标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba7f92-0c4d-42ce-ae11-0e9d00602597",
   "metadata": {},
   "source": [
    "程序段1.8实现了层标准化的计算逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda8812b-9318-41de-adeb-3f8cab48cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义的层标准化\n",
    "class LayerNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, eps:float=10**-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(d_model)) # alpha是可训练参数\n",
    "        self.bias = nn.Parameter(torch.zeros(d_model)) # bias是可训练参数\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        mean = x.mean(dim = -1, keepdim = True) # (batch_size, seq_len, 1)\n",
    "        std = x.std(dim = -1, keepdim = True) # (batch_size, seq_len, 1)\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "907cc1a1-0bc5-487f-ac04-4425919a0b73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "层标准化之前的X：\n",
      " tensor([[[ -7.3791,   2.1448,   0.7829,  ...,   6.9030,   9.3861,   0.0000],\n",
      "         [  2.5428,  -5.7630,   0.0000,  ...,  -1.1007, -13.4121,   5.6321],\n",
      "         [-13.7783,   1.8668, -11.1591,  ...,  -8.8603,  -7.9482, -14.5927],\n",
      "         ...,\n",
      "         [ -5.5646,   4.3508,  -5.0623,  ...,   3.9187,  -1.9886,  -4.7542],\n",
      "         [  3.5289,   2.2999,   5.4827,  ..., -10.9634,  -9.4228,  -3.6248],\n",
      "         [ 11.2869,   9.8718,  -4.5895,  ...,   4.5762,  -7.1419,  -3.2897]],\n",
      "\n",
      "        [[  5.2099,  13.9342,   1.2197,  ..., -14.3893,  18.5205,  -5.3147],\n",
      "         [  8.7584,  -3.1686,   0.0000,  ..., -10.5332,   9.2925,  10.2795],\n",
      "         [  2.5875,   7.0298,   4.4812,  ...,  -7.1233,   6.6587,   5.7045],\n",
      "         ...,\n",
      "         [  2.9565,   4.6786,   6.4331,  ...,   5.4211, -13.6371,   6.2226],\n",
      "         [ 11.8787,   4.6417,  -0.0000,  ...,  11.8295,   3.2298,  -9.1687],\n",
      "         [-13.2332,  12.3829, -20.7847,  ..., -10.4894,  13.8055,  19.5107]],\n",
      "\n",
      "        [[-15.7769,   0.0000,  11.1875,  ...,  -6.2981,  -3.5375,   1.0772],\n",
      "         [ -3.0078,   9.9508,  11.1900,  ...,  -9.0136,   3.0220,  12.0540],\n",
      "         [ 11.6623,   0.0000,   3.5723,  ...,  -4.1414,  -8.7376,  17.6145],\n",
      "         ...,\n",
      "         [  8.2062,   3.7300,  -1.1794,  ...,   7.5920,  -3.1807,   5.4067],\n",
      "         [  0.0000,   3.1008,   1.9525,  ...,  -0.6346, -10.5837,   2.0074],\n",
      "         [ -2.7631,  11.2192,   8.0144,  ...,  -8.7495, -12.6657,   5.1281]],\n",
      "\n",
      "        [[ 11.1633, -10.2949,   6.9224,  ..., -11.3412,  -9.4075, -12.3999],\n",
      "         [  9.3046,   1.0112,  -3.6027,  ...,  -0.0000, -20.0191,  -7.6482],\n",
      "         [ 12.3958,  -7.3361, -16.3926,  ...,   1.4754, -17.2759,  -2.9700],\n",
      "         ...,\n",
      "         [  6.7461,  15.8179,   7.2919,  ..., -15.3684, -11.1070, -17.8107],\n",
      "         [  9.0796,   2.0373,  -0.6710,  ...,  -0.0000,  -9.8612,   8.1702],\n",
      "         [  2.2803,  -1.5478,  -7.7647,  ...,  -0.0000,  -6.4596,   3.2217]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "\n",
      "自定义的层标准化：\n",
      " tensor([[[-0.6780,  0.2937,  0.1548,  ...,  0.7792,  1.0326,  0.0749],\n",
      "         [ 0.3832, -0.5586,  0.0948,  ..., -0.0300, -1.4260,  0.7335],\n",
      "         [-1.4918,  0.2864, -1.1941,  ..., -0.9329, -0.8292, -1.5844],\n",
      "         ...,\n",
      "         [-0.4909,  0.5723, -0.4370,  ...,  0.5260, -0.1074, -0.4040],\n",
      "         [ 0.3945,  0.2598,  0.6086,  ..., -1.1935, -1.0247, -0.3894],\n",
      "         [ 1.0598,  0.9237, -0.4671,  ...,  0.4144, -0.7125, -0.3421]],\n",
      "\n",
      "        [[ 0.5695,  1.5422,  0.1245,  ..., -1.6159,  2.0536, -0.6041],\n",
      "         [ 0.9981, -0.3431,  0.0132,  ..., -1.1713,  1.0582,  1.1692],\n",
      "         [ 0.3063,  0.8302,  0.5297,  ..., -0.8390,  0.7865,  0.6739],\n",
      "         ...,\n",
      "         [ 0.3218,  0.5152,  0.7123,  ...,  0.5986, -1.5422,  0.6887],\n",
      "         [ 1.4968,  0.5684, -0.0270,  ...,  1.4905,  0.3873, -1.2031],\n",
      "         [-1.4091,  1.3960, -2.2360,  ..., -1.1086,  1.5518,  2.1765]],\n",
      "\n",
      "        [[-1.9059,  0.0260,  1.3960,  ..., -0.7452, -0.4072,  0.1579],\n",
      "         [-0.3381,  1.0313,  1.1623,  ..., -0.9727,  0.2991,  1.2536],\n",
      "         [ 1.2342,  0.0106,  0.3854,  ..., -0.4240, -0.9062,  1.8588],\n",
      "         ...,\n",
      "         [ 0.8384,  0.3641, -0.1561,  ...,  0.7733, -0.3681,  0.5417],\n",
      "         [-0.0376,  0.3789,  0.2247,  ..., -0.1228, -1.4589,  0.2320],\n",
      "         [-0.3734,  1.4479,  1.0305,  ..., -1.1532, -1.6633,  0.6545]],\n",
      "\n",
      "        [[ 1.2368, -1.2074,  0.7538,  ..., -1.3266, -1.1064, -1.4472],\n",
      "         [ 1.0430,  0.1381, -0.3653,  ...,  0.0278, -2.1564, -0.8066],\n",
      "         [ 1.4677, -0.8337, -1.8900,  ...,  0.1940, -1.9930, -0.3245],\n",
      "         ...,\n",
      "         [ 0.6982,  1.6714,  0.7567,  ..., -1.6743, -1.2171, -1.9363],\n",
      "         [ 1.1010,  0.2175, -0.1222,  ..., -0.0381, -1.2752,  0.9869],\n",
      "         [ 0.2979, -0.1807, -0.9579,  ...,  0.0128, -0.7947,  0.4156]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n",
      "Pytorch定义的层标准化：\n",
      " tensor([[[-0.6787,  0.2940,  0.1549,  ...,  0.7800,  1.0336,  0.0750],\n",
      "         [ 0.3835, -0.5592,  0.0949,  ..., -0.0300, -1.4274,  0.7342],\n",
      "         [-1.4933,  0.2867, -1.1953,  ..., -0.9338, -0.8300, -1.5860],\n",
      "         ...,\n",
      "         [-0.4914,  0.5729, -0.4374,  ...,  0.5265, -0.1075, -0.4044],\n",
      "         [ 0.3949,  0.2601,  0.6092,  ..., -1.1947, -1.0257, -0.3898],\n",
      "         [ 1.0608,  0.9246, -0.4675,  ...,  0.4148, -0.7132, -0.3424]],\n",
      "\n",
      "        [[ 0.5700,  1.5438,  0.1247,  ..., -1.6175,  2.0556, -0.6047],\n",
      "         [ 0.9991, -0.3435,  0.0132,  ..., -1.1725,  1.0592,  1.1703],\n",
      "         [ 0.3066,  0.8311,  0.5302,  ..., -0.8398,  0.7872,  0.6746],\n",
      "         ...,\n",
      "         [ 0.3221,  0.5157,  0.7130,  ...,  0.5992, -1.5437,  0.6893],\n",
      "         [ 1.4982,  0.5690, -0.0270,  ...,  1.4919,  0.3877, -1.2043],\n",
      "         [-1.4104,  1.3974, -2.2382,  ..., -1.1097,  1.5533,  2.1786]],\n",
      "\n",
      "        [[-1.9078,  0.0260,  1.3973,  ..., -0.7459, -0.4076,  0.1581],\n",
      "         [-0.3384,  1.0323,  1.1634,  ..., -0.9737,  0.2994,  1.2548],\n",
      "         [ 1.2354,  0.0106,  0.3858,  ..., -0.4244, -0.9071,  1.8606],\n",
      "         ...,\n",
      "         [ 0.8392,  0.3645, -0.1562,  ...,  0.7740, -0.3685,  0.5423],\n",
      "         [-0.0376,  0.3792,  0.2249,  ..., -0.1229, -1.4604,  0.2323],\n",
      "         [-0.3738,  1.4493,  1.0315,  ..., -1.1543, -1.6649,  0.6552]],\n",
      "\n",
      "        [[ 1.2381, -1.2086,  0.7545,  ..., -1.3279, -1.1074, -1.4486],\n",
      "         [ 1.0440,  0.1383, -0.3656,  ...,  0.0278, -2.1585, -0.8074],\n",
      "         [ 1.4692, -0.8345, -1.8919,  ...,  0.1942, -1.9950, -0.3248],\n",
      "         ...,\n",
      "         [ 0.6988,  1.6730,  0.7574,  ..., -1.6759, -1.2183, -1.9382],\n",
      "         [ 1.1021,  0.2177, -0.1224,  ..., -0.0381, -1.2764,  0.9879],\n",
      "         [ 0.2982, -0.1808, -0.9588,  ...,  0.0128, -0.7955,  0.4160]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "LN = LayerNormalization(d_model)  # 用自己定义的层标准化\n",
    "x1_ln = LN(X)  # X样本做层标准化\n",
    "LN2 = nn.LayerNorm(d_model)  # 用 pytorch 预定义的层标准化函数\n",
    "x2_ln = LN2(X)\n",
    "print(f'层标准化之前的X：\\n {X}')\n",
    "print(f'\\n自定义的层标准化：\\n {x1_ln}')\n",
    "print(f'\\nPytorch定义的层标准化：\\n {x2_ln}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f31c4-cfb8-4571-971c-4fc4dd693490",
   "metadata": {},
   "source": [
    "### 1.9 前馈网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b08b94-dd07-47dc-b1d3-f143ba5ce5be",
   "metadata": {},
   "source": [
    "程序段1.9实现了前馈网络的计算逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8540a8b0-3366-4b82-8f91-7209c1a6c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):  # 前馈网络\n",
    "\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff) # 第一层宽度为 d_ff = 4 * d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model) \n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, seq_len, d_model) --> (batch_size, seq_len, d_ff)  \n",
    "        x = self.linear_1(self.norm(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # (batch_size, seq_len, d_ff) --> (batch_size, seq_len, d_model)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4720285-297d-47d1-97a0-3560cf32af1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前馈网络结合残差块之后的X的形状：\n",
      " torch.Size([4, 8, 512])\n",
      "\n",
      "前馈网络结合残差块之后的X：\n",
      " tensor([[[-7.1005e+00,  1.9521e+00,  7.4475e-01,  ...,  7.0929e+00,\n",
      "           9.3393e+00,  3.2801e-01],\n",
      "         [ 2.8510e+00, -5.8337e+00,  1.8062e-01,  ..., -1.1898e+00,\n",
      "          -1.3069e+01,  5.2116e+00],\n",
      "         [-1.3757e+01,  1.4670e+00, -1.1211e+01,  ..., -8.8951e+00,\n",
      "          -7.7223e+00, -1.5258e+01],\n",
      "         ...,\n",
      "         [-5.4868e+00,  4.1346e+00, -5.1322e+00,  ...,  4.1459e+00,\n",
      "          -1.2711e+00, -4.8632e+00],\n",
      "         [ 4.0392e+00,  1.8754e+00,  5.5188e+00,  ..., -1.0963e+01,\n",
      "          -8.7869e+00, -3.9294e+00],\n",
      "         [ 1.1364e+01,  9.7671e+00, -4.5206e+00,  ...,  4.5762e+00,\n",
      "          -7.1844e+00, -3.4258e+00]],\n",
      "\n",
      "        [[ 5.5804e+00,  1.3896e+01,  1.2083e+00,  ..., -1.4566e+01,\n",
      "           1.8533e+01, -5.3147e+00],\n",
      "         [ 9.1912e+00, -3.0121e+00, -1.1040e-01,  ..., -1.0125e+01,\n",
      "           9.3409e+00,  1.0558e+01],\n",
      "         [ 2.7110e+00,  7.1455e+00,  4.4812e+00,  ..., -6.5864e+00,\n",
      "           6.9287e+00,  6.1653e+00],\n",
      "         ...,\n",
      "         [ 3.0231e+00,  4.3970e+00,  7.0978e+00,  ...,  5.4211e+00,\n",
      "          -1.3619e+01,  6.5378e+00],\n",
      "         [ 1.2348e+01,  4.5752e+00,  2.8614e-01,  ...,  1.1975e+01,\n",
      "           3.2692e+00, -9.1687e+00],\n",
      "         [-1.2643e+01,  1.2454e+01, -2.0785e+01,  ..., -1.0140e+01,\n",
      "           1.3851e+01,  1.9621e+01]],\n",
      "\n",
      "        [[-1.5554e+01,  0.0000e+00,  1.0711e+01,  ..., -6.2343e+00,\n",
      "          -3.5375e+00,  1.1986e+00],\n",
      "         [-2.9167e+00,  1.0229e+01,  1.0610e+01,  ..., -8.6619e+00,\n",
      "           3.1556e+00,  1.1999e+01],\n",
      "         [ 1.1877e+01, -1.5394e-01,  2.9549e+00,  ..., -4.0553e+00,\n",
      "          -8.5712e+00,  1.7380e+01],\n",
      "         ...,\n",
      "         [ 8.6342e+00,  3.3092e+00, -1.0418e+00,  ...,  7.2526e+00,\n",
      "          -3.4030e+00,  5.5909e+00],\n",
      "         [ 4.4126e-01,  3.1664e+00,  1.8302e+00,  ..., -4.5914e-01,\n",
      "          -1.0426e+01,  2.0659e+00],\n",
      "         [-2.2268e+00,  1.1189e+01,  7.9210e+00,  ..., -8.3388e+00,\n",
      "          -1.2535e+01,  4.6881e+00]],\n",
      "\n",
      "        [[ 1.1007e+01, -1.0487e+01,  6.7428e+00,  ..., -1.1161e+01,\n",
      "          -9.1349e+00, -1.2677e+01],\n",
      "         [ 9.1143e+00,  1.0112e+00, -3.6860e+00,  ...,  0.0000e+00,\n",
      "          -1.9766e+01, -7.8407e+00],\n",
      "         [ 1.2396e+01, -7.4607e+00, -1.6189e+01,  ...,  1.9808e+00,\n",
      "          -1.6943e+01, -2.9883e+00],\n",
      "         ...,\n",
      "         [ 7.4253e+00,  1.5550e+01,  7.2919e+00,  ..., -1.5333e+01,\n",
      "          -1.0779e+01, -1.7895e+01],\n",
      "         [ 9.0796e+00,  2.1899e+00, -6.7128e-01,  ...,  9.7602e-02,\n",
      "          -9.8523e+00,  7.4910e+00],\n",
      "         [ 2.7267e+00, -1.6209e+00, -7.5693e+00,  ..., -3.9447e-03,\n",
      "          -6.2644e+00,  3.2094e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "feed_forward = FeedForward(d_model, d_ff, dropout)  # 前馈网络\n",
    "X = X + feed_forward(X)   # 残差块\n",
    "\n",
    "print(f'前馈网络结合残差块之后的X的形状：\\n {X.shape}')\n",
    "print(f'\\n前馈网络结合残差块之后的X：\\n {X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a7ebb-2140-4adb-93ac-695f40fd50cc",
   "metadata": {},
   "source": [
    "### 1.10 Transformer编码器定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b8346-8d75-49da-a8e1-6118afa24c28",
   "metadata": {},
   "source": [
    "程序段1.10：编码器单层和整体的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219e9ff7-b248-43b9-81f3-5f811f5f24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):  # 编码器的单层定义\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 heads: int,\n",
    "                 d_ff: int = 2048,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.self_attention = MultiHeadAttention(d_model, heads, dropout)  # 多头自注意力\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)  # 前馈网络\n",
    "        \n",
    "    # 编码器输入 x 和 掩码矩阵 src_mask\n",
    "    def forward(self, x, src_mask):\n",
    "        # 多头注意力计算，注意力残差块\n",
    "        x = x + self.self_attention(self.norm(x),   # Q\n",
    "                                    self.norm(x),   # K\n",
    "                                    self.norm(x),   # V\n",
    "                                    src_mask)     # 填充掩码矩阵\n",
    "        # 前馈网络计算，残差块\n",
    "        x = x + self.feed_forward(self.norm(x))   \n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):  # 编码器\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 heads: int,\n",
    "                 d_ff: int = 2048,\n",
    "                 dropout: float = 0.1, \n",
    "                 num_layers: int = 6):\n",
    "        \n",
    "        super().__init__()\n",
    "        # 创建编码器各层\n",
    "        encoder_blocks = []\n",
    "        for _ in range(num_layers):\n",
    "            encoder_layer = EncoderLayer(d_model, heads, d_ff, dropout)\n",
    "            encoder_blocks.append(encoder_layer)\n",
    "        self.layers = nn.ModuleList(encoder_blocks)   # 编码器各层列表\n",
    "    \n",
    "    # 编码器输入 x 和 填充掩码矩阵 src_mask\n",
    "    def forward(self, x, src_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)  # 连接各个编码器层\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62185377-36e9-4552-8aa2-3a0babd74ccc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码器输出X的形状：\n",
      " torch.Size([4, 8, 512])\n",
      "编码器输出X的内容：\n",
      " tensor([[[ -6.9696,   2.0169,   1.7395,  ...,   5.6665,  10.2217,   0.8741],\n",
      "         [  3.5567,  -4.6368,   0.0454,  ...,  -2.2614, -13.6203,   5.2182],\n",
      "         [-12.5085,   1.6310, -10.4852,  ...,  -9.9112,  -7.5822, -14.9854],\n",
      "         ...,\n",
      "         [ -5.0721,   4.7207,  -5.2429,  ...,   3.1427,  -1.5077,  -4.7265],\n",
      "         [  3.9986,   2.7173,   6.1194,  ..., -12.2413,  -8.1812,  -3.7893],\n",
      "         [ 11.7539,  10.0915,  -4.7571,  ...,   3.1658,  -6.9866,  -2.9779]],\n",
      "\n",
      "        [[  6.4644,  14.3475,   1.0192,  ..., -15.8006,  19.5611,  -4.8293],\n",
      "         [  9.8280,  -3.5177,   0.1406,  ..., -11.4785,   9.8215,  10.5814],\n",
      "         [  2.4028,   6.3767,   4.5184,  ...,  -6.8328,   8.0347,   6.7899],\n",
      "         ...,\n",
      "         [  2.8619,   4.0514,   7.9163,  ...,   4.9041, -13.2488,   4.7620],\n",
      "         [ 12.6679,   4.4329,   0.8263,  ...,  11.2225,   3.1525,  -8.7614],\n",
      "         [-12.9275,  12.8445, -20.0032,  ..., -10.8710,  14.1446,  19.8254]],\n",
      "\n",
      "        [[-14.8230,   1.1431,  11.0152,  ...,  -6.1138,  -3.7429,   0.6467],\n",
      "         [ -2.5414,  10.1684,  11.6662,  ...,  -9.6083,   2.9989,  11.3391],\n",
      "         [ 10.8711,   0.7626,   3.4276,  ...,  -4.5353,  -9.7470,  16.4928],\n",
      "         ...,\n",
      "         [  8.3258,   4.2337,  -1.0542,  ...,   6.8366,  -2.8355,   4.8299],\n",
      "         [  1.2884,   3.8695,   2.4325,  ...,  -1.8829, -10.1784,   1.8179],\n",
      "         [ -3.0339,  12.1319,   8.4491,  ...,  -9.2696, -12.0009,   3.7110]],\n",
      "\n",
      "        [[ 10.8784, -11.0197,   7.1878,  ..., -12.0214,  -8.8962, -13.1355],\n",
      "         [  8.8558,   1.6025,  -3.3972,  ...,  -1.1748, -20.0096,  -8.1445],\n",
      "         [ 12.1499,  -6.6996, -15.7960,  ...,   1.5770, -16.2425,  -2.0887],\n",
      "         ...,\n",
      "         [  7.2871,  15.2599,   7.7322,  ..., -15.7742, -10.1439, -17.3759],\n",
      "         [  8.4837,   2.6382,   0.0645,  ...,  -0.8061,  -9.2160,   7.1928],\n",
      "         [  2.1080,  -2.0898,  -6.9667,  ...,  -0.3542,  -6.6095,   2.8617]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "num_layers = 6  # 编码器层数\n",
    "d_model = 512\n",
    "heads = 8\n",
    "dropout = 0.1\n",
    "d_ff = 2048\n",
    "# 创建编码器\n",
    "encoder = Encoder(d_model, heads, d_ff, dropout, num_layers)\n",
    "src_mask = None\n",
    "X = encoder(X, src_mask)  # 编码器推理\n",
    "print(f'编码器输出X的形状：\\n {X.shape}')\n",
    "print(f'编码器输出X的内容：\\n {X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3c748-3044-44a6-a4a2-03f5952f0f87",
   "metadata": {},
   "source": [
    "### 1.11 Transformer解码器定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0be56b-5112-4a37-9a6c-97cc0a06f514",
   "metadata": {},
   "source": [
    "程序段1.11：解码器单层和整体的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e59c94d-5b42-4ce9-b7b0-515a468308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):  # 解码器的单层定义\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 heads: int, \n",
    "                 d_ff: int = 2048, \n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.self_attention = MultiHeadAttention(d_model, heads, dropout)   # 掩码多头自注意力\n",
    "        self.cross_attention = MultiHeadAttention(d_model, heads, dropout)  # 交叉多头注意力\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)  # 前馈网络\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # 多头自注意力计算， 注意力残差块，输入的是 Q 、K、V，tgt_mask 解码器掩码\n",
    "        x = x + self.self_attention(self.norm(x), self.norm(x), self.norm(x), tgt_mask)\n",
    "        # 交叉多头注意力计算， 注意力残差块\n",
    "        x = x + self.cross_attention(self.norm(x),  # 解码器上一层输出的 Q矩阵\n",
    "                                     self.norm(encoder_output),   # 编码器输出的 K矩阵\n",
    "                                     self.norm(encoder_output),   # 编码器输出的 V矩阵\n",
    "                                     src_mask)     # src_mask 表示填充掩码\n",
    "        # 前馈网络计算， 残差块\n",
    "        x = x + self.feed_forward(self.norm(x))   \n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):   # 解码器\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 heads: int, \n",
    "                 d_ff: int = 2048, \n",
    "                 dropout: float = 0.1, \n",
    "                 num_layers: int = 6):\n",
    "        \n",
    "        super().__init__()\n",
    "        # 创建解码器各层\n",
    "        decoder_blocks = []\n",
    "        for _ in range(num_layers):\n",
    "            decoder_layer = DecoderLayer(d_model, heads, d_ff, dropout)\n",
    "            decoder_blocks.append(decoder_layer)\n",
    "        self.layers = nn.ModuleList(decoder_blocks)   # 解码器各层列表\n",
    "    \n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)  # 连接各层\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3128b917-9eef-4e75-9072-731684d506d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解码器输出X的形状：\n",
      " torch.Size([4, 8, 512])\n",
      "解码器输出的X内容：\n",
      " tensor([[[ -6.6993,   2.1376,   0.7858,  ...,   5.9735,  10.4620,  -0.2455],\n",
      "         [  3.8111,  -4.0369,  -1.0978,  ...,  -2.3895, -13.1481,   4.6516],\n",
      "         [-11.8709,   3.3796, -10.1133,  ...,  -9.0457,  -7.6680, -15.5601],\n",
      "         ...,\n",
      "         [ -4.1956,   4.9070,  -5.7385,  ...,   3.4915,  -1.3652,  -5.5563],\n",
      "         [  4.3013,   2.8888,   4.9513,  ..., -11.2582,  -9.6134,  -5.4908],\n",
      "         [ 12.3409,  11.4703,  -5.1791,  ...,   2.9760,  -6.9357,  -4.3056]],\n",
      "\n",
      "        [[  6.8585,  13.3532,   0.4404,  ..., -16.0193,  19.0073,  -3.9782],\n",
      "         [  9.9097,  -4.5325,  -0.1822,  ..., -13.1542,  10.2615,  10.2845],\n",
      "         [  1.8819,   7.1601,   4.4242,  ...,  -7.0217,   7.2066,   7.6939],\n",
      "         ...,\n",
      "         [  2.7568,   4.4886,   7.6113,  ...,   3.4948, -12.9694,   5.8626],\n",
      "         [ 13.5333,   4.8222,   0.4031,  ...,   9.4285,   3.4756,  -9.1734],\n",
      "         [-12.6108,  12.9711, -19.6789,  ..., -11.6283,  12.9637,  20.3004]],\n",
      "\n",
      "        [[-14.4907,   1.3743,  10.5220,  ...,  -4.6493,  -1.9559,   1.4524],\n",
      "         [ -3.2269,  10.3773,  10.8631,  ...,  -9.5202,   4.9855,  12.2348],\n",
      "         [ 11.4685,   0.5033,   2.8703,  ...,  -5.1016,  -8.5405,  17.0625],\n",
      "         ...,\n",
      "         [  8.7989,   4.4379,  -1.5994,  ...,   7.6886,  -1.6131,   5.1974],\n",
      "         [  2.8520,   4.5478,   3.0290,  ...,  -0.6029,  -9.3334,   2.6892],\n",
      "         [ -2.5886,  12.8560,   8.5438,  ...,  -9.0182, -11.3165,   3.2135]],\n",
      "\n",
      "        [[ 11.8622, -11.4049,   6.2750,  ..., -13.6953,  -8.2542, -11.5237],\n",
      "         [  9.5873,   1.5235,  -4.6415,  ...,  -2.5005, -19.1906,  -6.7798],\n",
      "         [ 13.2013,  -6.2785, -17.0630,  ...,   0.6694, -16.0633,  -1.3097],\n",
      "         ...,\n",
      "         [  7.6148,  15.6238,   6.8211,  ..., -15.7249, -10.8361, -16.4683],\n",
      "         [  8.6829,   2.9202,  -0.1906,  ...,  -0.6605,  -8.7534,   8.9490],\n",
      "         [  1.7686,  -2.7880,  -7.5910,  ...,  -0.0232,  -6.4047,   3.6410]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "num_layers = 6  # 解码器层数\n",
    "d_model = 512\n",
    "heads = 8\n",
    "dropout = 0.1\n",
    "d_ff = 2048\n",
    "\n",
    "# 创建解码器\n",
    "decoder = Decoder(d_model, heads, d_ff, dropout, num_layers)\n",
    "src_mask = None\n",
    "tgt_mask = None\n",
    "encoder_output = X  #  假定 X 是编码器的输出 \n",
    "\n",
    "# 为便于演示，这里解码器的输入暂时也用 X 表示\n",
    "X = decoder(X, encoder_output, src_mask, tgt_mask)  # 解码器推理\n",
    "print(f'解码器输出X的形状：\\n {X.shape}')\n",
    "print(f'解码器输出的X内容：\\n {X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35430cd0-1039-45d5-ba82-bad4a1b9e2d6",
   "metadata": {},
   "source": [
    "### 1.12 Transformer模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ef56a89-9cd0-46d9-9c2d-d7782790422d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 字典映射层，将解码器输出的词向量映射为词典长度的向量\n",
    "class OutputLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size) # 映射回词典空间\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a94fa91c-10f9-4de6-9e62-53f14c7f3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):  # Transformer 模型定义\n",
    "\n",
    "    def __init__(self, \n",
    "          src_vocab_size: int,   # 源词典大小\n",
    "          tgt_vocab_size: int,   # 目标词典大小\n",
    "          src_seq_len: int,      # 源序列最大长度\n",
    "          tgt_seq_len: int,      # 目标序列最大长度\n",
    "          d_model: int = 512,    # 模型宽度\n",
    "          heads: int=8,          # 注意力头数\n",
    "          num_encoder_layers: int = 6,    # 编码器层数\n",
    "          num_decoder_layers: int = 6,    # 解码器层数\n",
    "          d_ff: int = 2048,      # 前馈网络第一层的宽度\n",
    "          dropout: float = 0.1):\n",
    "        \n",
    "        super().__init__()\n",
    "        # 创建词向量输入层\n",
    "        self.src_embed = InputEmbeddings(src_vocab_size, d_model)\n",
    "        self.tgt_embed = InputEmbeddings(tgt_vocab_size, d_model)\n",
    "\n",
    "        # 创建词向量位置编码层\n",
    "        self.src_pos = PositionalEncoding(src_seq_len, d_model, dropout)\n",
    "        self.tgt_pos = PositionalEncoding(tgt_seq_len, d_model, dropout)       \n",
    "        # 创建编码器\n",
    "        self.encoder = Encoder(d_model, heads, d_ff, dropout, num_encoder_layers)\n",
    "        # 创建解码器\n",
    "        self.decoder = Decoder(d_model, heads, d_ff, dropout, num_decoder_layers)      \n",
    "        # 词向量投射到字典空间\n",
    "        self.project_layer = OutputLayer(d_model, tgt_vocab_size)\n",
    "\n",
    "    def encode(self, src, src_mask):  # 编码器编码过程\n",
    "        # (batch, seq_len, d_model)\n",
    "        src = self.src_embed(src)  # 编码器词嵌入\n",
    "        src, _ = self.src_pos(src)   # 编码器的位置编码\n",
    "        encoder_output = self.encoder(src, src_mask)  # 编码器推理\n",
    "        return encoder_output   # 输出的形状维度：(batch_size, seq_len, d_model)\n",
    "    \n",
    "    def decode(self, \n",
    "               tgt: torch.Tensor,\n",
    "               encoder_output: torch.Tensor, \n",
    "               src_mask: torch.Tensor,  \n",
    "               tgt_mask: torch.Tensor):\n",
    "        # (batch, seq_len, d_model)\n",
    "        tgt = self.tgt_embed(tgt)   # 解码器词嵌入\n",
    "        tgt, _ = self.tgt_pos(tgt)     # 解码器的位置编码\n",
    "        decoder_output = self.decoder(tgt, encoder_output, src_mask, tgt_mask)  # 解码器推理\n",
    "        return decoder_output  # 输出的形状维度：(batch_size, seq_len, d_model)\n",
    "    def output_layer(self, x):\n",
    "        # (batch, seq_len, vocab_size)\n",
    "        return self.project_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f0a0bb6-c358-433f-abf1-de33a1eb3d8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码器输入的形状：\n",
      " torch.Size([4, 8])\n",
      "\n",
      "编码器输入的内容：\n",
      " tensor([[ 4118,  7961, 15944, 20728, 18026,  2926,  4422, 14583],\n",
      "        [ 1391, 13255, 18307,  5554, 10778, 14992, 20213, 10499],\n",
      "        [ 3916,  6704, 10057, 18068, 19197,  2098, 15748,  5110],\n",
      "        [ 8677, 13728, 15260, 19508,  5855,  8106,  7820, 16374]])\n",
      "\n",
      "解码器输入的形状：\n",
      " torch.Size([4, 8])\n",
      "\n",
      "解码器输入的内容：\n",
      " tensor([[29213, 19024,  8361, 19524,   825, 15783, 25248, 25059],\n",
      "        [15110, 10750, 25489,   993, 20811,  8838, 22323, 23622],\n",
      "        [ 7417, 27051, 21660, 27075, 15680,  3570, 12608, 15916],\n",
      "        [21175,  5771, 23228, 21306, 28363, 17342,  4529,  4211]])\n",
      "\n",
      "编码器掩码矩阵的形状：\n",
      " torch.Size([1, 8, 8])\n",
      "\n",
      "解码器掩码矩阵的形状：\n",
      " torch.Size([1, 8, 8])\n",
      "Transformer输出的形状：\n",
      " torch.Size([4, 30522])\n",
      "Transformer输出的内容：\n",
      " tensor([[-2.2468e-01,  9.3363e-01, -4.9548e-02,  ..., -5.1730e-02,\n",
      "          8.5177e-01,  3.4542e-01],\n",
      "        [-8.5632e-01,  4.6375e-01,  6.7897e-01,  ..., -5.5763e-04,\n",
      "          5.7953e-01,  5.4860e-01],\n",
      "        [-1.3713e+00,  4.3081e-01,  4.3034e-02,  ...,  3.5451e-01,\n",
      "          1.1747e+00,  9.6837e-01],\n",
      "        [-6.9081e-01,  5.2097e-01,  8.5769e-01,  ...,  2.6632e-01,\n",
      "          9.9536e-01,  5.6778e-01]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "src_seq_len = 8  #  源序列最大长度\n",
    "tgt_seq_len = 8  #  目标序列最大长度\n",
    "src_vocab_size = 21128  # 设置编码器端的词典大小\n",
    "tgt_vocab_size = 30522  # 设置解码器词端的典大小\n",
    "d_model = 512     # 设置模型维度\n",
    "heads = 8   # 注意力头数\n",
    "num_encoder_layers = 6   # 编码器层数\n",
    "num_decoder_layers = 6   # 解码器层数\n",
    "d_ff = 2048   # 前馈网络第一层的宽度\n",
    "dropout = 0.1   \n",
    "batch_size = 4   # 设置批次大小\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 创建 Transformer 模型实例\n",
    "model = Transformer(src_vocab_size, \n",
    "              tgt_vocab_size, \n",
    "              src_seq_len, \n",
    "              tgt_seq_len, \n",
    "              d_model, \n",
    "              heads, \n",
    "              num_encoder_layers, \n",
    "              num_decoder_layers, \n",
    "              d_ff,\n",
    "              dropout)\n",
    "\n",
    "# 初始化模型参数，对于维度大于 1 的参数，使用 Xavier 均匀初始化方法进行初始化\n",
    "for p in model.parameters():  # 遍历模型中的可学习参数 \n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "# 将模型移到正确的设备\n",
    "model = model.to(device)\n",
    "\n",
    "# 使用 torch.randint 生成随机整数张量 src，取值范围为 [0, src_vocab_size),表示编码器的输入\n",
    "src = torch.randint(0, src_vocab_size, (batch_size, src_seq_len))\n",
    "print(f'编码器输入的形状：\\n {src.shape}')\n",
    "print(f'\\n编码器输入的内容：\\n {src}')\n",
    "\n",
    "# 使用 torch.randint 生成随机整数张量 tgt，取值范围为 [0, tgt_vocab_size),表示解码器的输入\n",
    "tgt = torch.randint(0, tgt_vocab_size, (batch_size, tgt_seq_len))\n",
    "print(f'\\n解码器输入的形状：\\n {tgt.shape}')\n",
    "print(f'\\n解码器输入的内容：\\n {tgt}')\n",
    "\n",
    "# 掩码矩阵\n",
    "src_mask = torch.tril(torch.ones(src_seq_len, src_seq_len)).unsqueeze(0)\n",
    "tgt_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).unsqueeze(0)\n",
    "print(f'\\n编码器掩码矩阵的形状：\\n {src_mask.shape}')\n",
    "print(f'\\n解码器掩码矩阵的形状：\\n {tgt_mask.shape}')\n",
    "\n",
    "# 确保输入数据在正确的设备上\n",
    "src = src.to(device)\n",
    "tgt = tgt.to(device)\n",
    "src_mask = src_mask.to(device)\n",
    "tgt_mask = tgt_mask.to(device)\n",
    "\n",
    "# 编码器推理\n",
    "encoder_output = model.encode(src, src_mask)\n",
    "# 解码器推理\n",
    "decoder_output = model.decode(tgt, encoder_output, src_mask, tgt_mask)\n",
    "\n",
    "# 如果是训练模式，输出层投射时，decoder_output的维度不变\n",
    "# 如果是推理模式，用 decoder_output[:, -1]投射，即投射每个样本的最后一个词嵌入向量\n",
    "# 训练模式维度变化：(batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
    "# 推理模式维度变化： (batch, d_model) --> (batch, vocab_size)\n",
    "logits = model.output_layer(decoder_output[:,-1])\n",
    "\n",
    "print(f'Transformer输出的形状：\\n {logits.shape}')\n",
    "print(f'Transformer输出的内容：\\n {logits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946a989-6740-48d6-839f-8742a6dcc653",
   "metadata": {},
   "source": [
    "查看模型需要学习和训练的参数总量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "966d7322-c740-42bf-8d64-9f4ee0e13cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型可训练参数数量是: 86198074\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'模型可训练参数数量是: {trainable_params}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
